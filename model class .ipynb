{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making model using input and output\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs = inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.Input(shape=(32,32))\n",
    "y = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "model = tf.keras.Model(x,y)\n",
    "\n",
    "##model.compile(optimizer=\"rmsprop\", loss=None, metrics=None, loss_weights=None) #compiles the model\n",
    "\n",
    "#tf.keras.optimizers -> optimizers like rmsprop, sgd, adam\n",
    "#tf.keras.losses -> crossentropy loss\n",
    "#for models with multiple outputs a dictionary of losses can be passed\n",
    "\n",
    "#tf.keras.metrics -> accuracy, {binary, sparsecategorical, categorical} accuracies depending on the output shape and loss function used\n",
    "#loss_weights -> coefficients are scalar coefficients of the individual losses used to calculate the wighted sum of the losses\n",
    "\n",
    "#weighted_metrics -> list of metrics to be evaluated or calculated by the class_weight or sample_weight while testing and training\n",
    "#run_eagerly is kinda force run for the model that doesn't run in tf.function\n",
    "#steps_per_execution-> numbers of batches to run during each function call\n",
    "\n",
    "\n",
    "##model.fit(x,y,batch_size=None,epochs=1) #method trains the model for fixed number of epochs\n",
    "\n",
    "#x: input data -> an Numpy array or list of arrays for multiple inputs, a tf tensor or a list of tensors, a dict mapping names to corresponding array or tensors\n",
    "#y: target data -> it can be Numpy array, tensors, etc.\n",
    "\n",
    "#batch_size -> int/ none. batch_size is not to be mentioned if the data is sequence instances, generators or datasets.\n",
    "#epochs -> are number of iterations for which the data in form of batches is provided to train the model.\n",
    "#verbose -> 0,1,2. how one wants to see the training process\n",
    "#validation_split-> fraction of training data to be used as validation data. the model will set this accordingly \n",
    "#validation_data -> data on which any loss or model metrics are evaluated at the end of the epoch. The model will not train on this data.\n",
    "#shuffle -> (boolean) whether to shuffle the training data or not.\n",
    "#class_weight -> dictionary of mappings used to tell the model to pay more attention on the under-represented data during the training\n",
    "#sample_weight -> optional numpy array of weights for training samples used for weighting the loss function.\n",
    "#initial_epoch -> (int)epoch at which to start the training\n",
    "#steps_per_epoch -> (int) batches of the sample data to be passed before an epoch is completed. for tf tensors steps= Number of samples/ batch_size.\n",
    "#validation_steps -> only used if validation_data is provided. it is number of steps to draw before stopping performing validation at the end of each epoch.\n",
    "#validation_batch_size -> (integer or none). number of samples per validation batch. \n",
    "#validation_freq -> integer or tuple or list, etc. it specifies how many training epochs before which a new validation is run. \n",
    "#max_queue_size -> (int). used if input is passed as generator or keras.utils.Sequence input only.\n",
    "#workers-> (int). used if input is passed as generator or keras.utils.Sequence input only. max number of processes to spin up when using process based threading.\n",
    "#use_multiprocessing:(boolean) Used for generator or keras.utils.Sequence input. \n",
    "\n",
    "##model.evaluate(x,y,batch_size) #returns the loss value and metrics values for the model during test phase.\n",
    "#x -> input data \n",
    "#y -> target data \n",
    "#batch_size -> the number of samples to be passed st each epoch. default=32\n",
    "#verbose-> (0,1). Verbosity modes\n",
    "#sample_weight-> used to compute the loss or any metrics\n",
    "#steps->total number of steps per epoch\n",
    "#callbacks-> list of callbacks instances keras.callbacks.Callback\n",
    "#max_queue_size -> max queue size of the generator has a default 10 value.\n",
    "#workers -> max processes to spin up\n",
    "\n",
    "##model.predict(x,batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing) #generates output predictions for intput samples\n",
    "\n",
    "##model.train_on_batch(x,y=None,sample_weight,class_weight,reset_metrics, retrun_dict)#returns a single gradient update on a single bacth of data\n",
    "\n",
    "#reset_metrics-> (boolean) if true, the metrics returned will be only for this batch, if false, the metrics will be ccumulated for the whole batch\n",
    "#return_dict -> if true, loss and metric results are returned as dict. if false, returned as a list.\n",
    "\n",
    "##model.test_on_batch(x,y=None,sample_weight,reset_metrics, retrun_dict)#test the model on a single batch of samples\n",
    "#the method, similar to the model.train_on_batch method, returns scalar loss or list of scalar test losses/ metrics.\n",
    "\n",
    "##model.predict_on_batch(x)#returns predictions for a single batch of samples\n",
    "\n",
    "###run_eagerly property\n",
    "#tf.keras.Model.run_eagerly -> (boolean) whether to run the model step by step like a code or like a static graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model subclassing\n",
    "class mymodel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(mymodel,self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.dense2(x)\n",
    "    \n",
    "model = mymodel()\n",
    "model.call(inputs=tf.keras.Input(shape=(4,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model subclassing with dropout layer\n",
    "class mymodel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(mymodel, self).__init__()\n",
    "        \n",
    "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        \n",
    "        x= self.dense1(inputs)\n",
    "        if training:\n",
    "            x= self.dropout(x, training = training)\n",
    "            \n",
    "        return self.dense2(x)\n",
    "    \n",
    "model = mymodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model class methods\n",
    "Model.summary(line_length, print_fn, positions)\n",
    "\n",
    "Model.get_layer(name=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model saving and serialization API\n",
    "\n",
    "\"\"\"\n",
    "1. model.save(filepath, overwrite, include_optimizer, save_format, signatures, options)\n",
    "\n",
    "model can be saved in two formats namely HDF5 and SavedModel formats if built using the Sequential and Functional API\n",
    "only in SavedModel format if built by subclassing\n",
    "\n",
    "saved models can be reinstantiated via keras.models.load_model method. This returns a compiled ready to use model.\n",
    "\n",
    "the model_weights may have different names as per the layers they belong to, for eg. \"dense_1/kerne:0\"\n",
    "\n",
    "filepath- String, PathLike, path to SavedModel or H5 file to save the model.\n",
    "overwrite - overwriting the existing files or prompt the user manually\n",
    "include_optimizer - to save optimizer's state\n",
    "save_format - tf or h5 \n",
    "signatures  applicable to tf format only. \n",
    "options - (Optional) tf.saved_model.SaveOptions object that specifies options for saving the model\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#note: tf.keras.models.save_model and model_save() methods are almost similar with same arguments except model \n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0917 11:54:13.692442 4591152576 hdf5_format.py:224] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#tf.keras.models.save_model(model,filepath,overwrite=True,include_optimizer=True,save_format=None,signatures=None,options=None)\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import save_model\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(5, input_shape=(6,)),tf.keras.layers.Softmax()]\n",
    "                           )\n",
    "model.save('/tmp/model')\n",
    "loaded_model= tensorflow.keras.models.load_model('/tmp/model')\n",
    "x=tensorflow.random.uniform((10,6))\n",
    "assert np.allclose(model.predict(x), loaded_model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0917 11:51:49.913742 4591152576 hdf5_format.py:224] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#load_model function\n",
    "\n",
    "#tf.keras.models.load_model(filepath, custom_objects, compile=True, options=None)\n",
    "#custom_objects - dictionary for mapping names to to custom classes or sutom functions for deserialization\n",
    "#compile - (boolean) whether to compile a model or not\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow.keras.models import save_model\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(5, input_shape=(6,)),tf.keras.layers.Softmax()]\n",
    "                           )\n",
    "model.save('/tmp/model')\n",
    "loaded_model= tensorflow.keras.models.load_model('/tmp/model')\n",
    "x=tensorflow.random.uniform((10,6))\n",
    "assert np.allclose(model.predict(x), loaded_model.predict(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_weights method\n",
    "#Model.get_weights()\n",
    "\n",
    "#retrieves a list of numpy arrays as weights\n",
    "\n",
    "#set_weights method\n",
    "#Model.set_weiqhts(weights)\n",
    "#this method sets the weights \n",
    "\n",
    "#load_weights(filepath, by_name, skip_mismatch, options)\n",
    "#this method loads all layers with weights\n",
    "\n",
    "#by_name - if true, the weights can be loaded into the layers that have same name. This is useful during fine tuning and transfer learning. if false, the weights are loaded in order as per network topology. The architecture of the neural network should be same when the weights were saved. if the layers added after saving the model do't have weights then no matter how many layers are added it doesn't affect the order of the neural network.\n",
    "\n",
    "#this method returns same status object when weight file is loaded in tf format.\n",
    "#on the contrary, if the weight file is loaded in hdf5 format it return none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_config method\n",
    "#this function returns a python dictionary that has the configuration of the layer without the network information.\n",
    "\n",
    "#Model.get_config()\n",
    "\n",
    "#from_config method \n",
    "\n",
    "#Model.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_from_config fuction\n",
    "#tf.keras.models.model_from_config(config, custom_objects)\n",
    "#instantiates keras models from it's config\n",
    "\n",
    "#to_json method\n",
    "#Model.to_json()\n",
    "\n",
    "#returns a JSON string containing the network configuration\n",
    "\n",
    "#model_from_json function\n",
    "#tf.keras.models.model_from_json(json_string, custom_objects)\n",
    "#parses a JSON model configuration string and return a model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clone_model function\n",
    "#tf.keras.models.clone_model(model, input_tensors=None, clone_function=None)\n",
    "\n",
    "#An instance of Model reproducing the behavior of the original model, on top of new inputs tensors, using newly instantiated weights. The cloned model might behave differently from the original model if a custom clone_function modifies the layer.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
