{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD\n",
    "syntax: tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\", **kwargs)\n",
    "\n",
    "Stochastic gradient descent optimizer is based on the gradient descent algorithm. It updates the weights of a layer each time a neural network is trained with the data.\n",
    "\n",
    "The update rule is given by:\n",
    "\n",
    "1) when momentum is 0\n",
    "\n",
    "w=w-learning_rate*g\n",
    "\n",
    "where,\n",
    "\n",
    "w= weight \n",
    "\n",
    "learning_rate = alpha (mostly)\n",
    "\n",
    "g= the gradient dw/dt\n",
    "\n",
    "2) When momentum is larger than 0\n",
    "\n",
    "velocity = momentum*velocity - learning_rate * g\n",
    "\n",
    "w = w + velocity\n",
    "\n",
    "3) when nesterov=True, then\n",
    "velocity = momentum*velocity - learning_rate * g\n",
    "\n",
    "w = w + momentum*velocity - learning_rate * g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments\n",
    "\n",
    "1. learning_rate - learning rate is not hing but no. of steps taken by the function('s') curve to reach it optimum (minimum) value. It is a floating point value between 0.0001 to 0.1 that is passed as an argument to the optimizer.\n",
    "\n",
    "\n",
    "                            \n",
    "2. momentum - [float] (hyperparameter>=0) that accelerates the gradient descent in proper direction by dampening the oscillations. Its default value is 0.\n",
    "\n",
    "\n",
    "\n",
    "3. nesterov - [boolean] whether to apply nesterov momentum or not.\n",
    "\n",
    "\n",
    "\n",
    "4. name - optional name prefix for operations created when applying gradients.\n",
    "\n",
    "\n",
    "\n",
    "5. **kwargs - keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example Usage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "var = tf.Variable(1.0)\n",
    "loss = lambda: (var ** 2)/2.0         # d(loss)/d(var1) = var1\n",
    "step_count = opt.minimize(loss, [var]).numpy()\n",
    "# Step is `- learning_rate * grad`  \n",
    "var.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop \n",
    "\n",
    "syntax: \n",
    "\n",
    "tf.keras.optimizers.RMSprop(learning_rate=0.001,rho=0.9,momentu=0.0,epsilon=1e-07,centered=False,name=\"RMSprop\",**kwargs)\n",
    "\n",
    "1. Optimizer that implements the RMSprop algorithm.\n",
    "\n",
    "\n",
    "2. The gist of RMSprop is to:\n",
    "\n",
    "    Maintain a moving (discounted) average of the square of gradients\n",
    "    Divide the gradient by the root of this average\n",
    "\n",
    "\n",
    "3. This implementation of RMSprop uses plain momentum, not Nesterov momentum.\n",
    "\n",
    "\n",
    "4. The centered version additionally maintains a moving average of the gradients, and uses that average to estimate the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments \n",
    "\n",
    "1. learning_rate-  learning rate is not hing but no. of steps taken by the function('s') curve to reach it optimum (minimum) value. It is a floating point value between 0.0001 to 0.1 that is passed as an argument to the optimizer.\n",
    "\n",
    "\n",
    "2. rho- discounting factor for the gradient. Defaults to 0.9.\n",
    "\n",
    "\n",
    "3. momentum- A scalar or a scalar tensor. Defaults to 0.0\n",
    "\n",
    "\n",
    "4. epsilon - small constnt for numerical stability. \n",
    "\n",
    "\n",
    "5. centered - [boolean] If True, gradients are normalized by the estimated variance of the gradient; if False, by the uncentered second moment. Setting this to True may help with training, but is slightly more expensive in terms of computation and memory. Defaults to False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.683772"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examples\n",
    "import tensorflow as tf\n",
    "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
    "var1 = tf.Variable(10.0)\n",
    "loss = lambda: (var1 ** 2) / 2.0    # d(loss) / d(var1) = var1\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Adam\n",
    "\n",
    "syntax: tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "\n",
    "1. Optimizer that implements the Adam algorithm.\n",
    "\n",
    "2. Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments\n",
    "\n",
    "\n",
    "1. learning_rate: A Tensor, floating point value, or a schedule that is a tf.keras.optimizers.schedules.LearningRateSchedule, or a callable that takes no arguments and returns the actual value to use, The learning rate. Defaults to 0.001.\n",
    "    \n",
    "    \n",
    "2. beta_1: A float value or a constant float tensor, or a callable that takes no arguments and returns the actual value to use. The exponential decay rate for the 1st moment estimates. Defaults to 0.9.\n",
    "    \n",
    "    \n",
    "3.beta_2: A float value or a constant float tensor, or a callable that takes no arguments and returns the actual value to use, The exponential decay rate for the 2nd moment estimates. Defaults to 0.999.\n",
    "    \n",
    "    \n",
    "4.epsilon: A small constant for numerical stability. This epsilon is \"epsilon hat\" in the Kingma and Ba paper (in the formula just before Section 2.1), not the epsilon in Algorithm 1 of the paper. Defaults to 1e-7.\n",
    "    \n",
    "    \n",
    "5.amsgrad: Boolean. Whether to apply AMSGrad variant of this algorithm from the paper \"On the Convergence of Adam and beyond\". Defaults to False.\n",
    "    \n",
    "    \n",
    "6.name: Optional name for the operations created when applying gradients. Defaults to \"Adam\".\n",
    "    \n",
    "    \n",
    "7. **kwargs: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\". \"clipnorm\" (float) clips gradients by norm; \"clipvalue\" (float) clips gradients by value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "opt= tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "var1=tf.Variable(10.0)\n",
    "loss= lambda: (var1**2)/2.0\n",
    "\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adadelta\n",
    "\n",
    "syntax: tf.keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name=\"Adadelta\", **kwargs)\n",
    "   \n",
    "1. This is based on the stochastic gradient descent method with adaptive learning rate per dimension\n",
    "\n",
    "\n",
    "\n",
    "2. This algorithm addresses two drawbacks:\n",
    "    \n",
    "- The continual decay of learning rates throughout training\n",
    "\n",
    "- The need for a manually selected global learning rate\n",
    "\n",
    "\n",
    "3. Adadeltas adaptive learning approach allows it to learn even after updates have been done. Compared to adagrad, it is more robust and allows setting the initiali learning rate. It adapts lerning rates based on moving window of gradient updates rather than accumulating all past gradients.\n",
    "\n",
    "\n",
    "4. Near the gradient, In order to avoid overfitting and to converge,the epsilon constant in the numerator and denominator dominate past gradients and parameter updates which converge the learning rate to 1.\n",
    "\n",
    "the step size is small \n",
    "\n",
    "\n",
    "5. Generally, ADADELTA converges faster than ADAGRAD.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "\n",
    "\n",
    "1. learning_rate: A Tensor, floating point value, or a schedule that is a tf.keras.optimizers.schedules.LearningRateSchedule. The learning rate. To match the exact form in the original paper use 1.0.\n",
    "\n",
    "    \n",
    "2.rho: A Tensor or a floating point value. The decay rate.\n",
    "\n",
    "    \n",
    "3.epsilon: A Tensor or a floating point value. A constant epsilon used to better conditioning the grad update.\n",
    "\n",
    "    \n",
    "4.name: Optional name prefix for the operations created when applying gradients. Defaults to \"Adadelta\".\n",
    "    \n",
    "    \n",
    "5.**kwargs: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\". \"clipnorm\" (float) clips gradients by norm; \"clipvalue\" (float) clips gradients by value.\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999859"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "opt= tf.keras.optimizers.Adadelta(learning_rate=0.1)\n",
    "var1=tf.Variable(10.0)\n",
    "loss= lambda: (var1**2)/2.0\n",
    "\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adagrad class\n",
    "\n",
    "syntax: tf.keras.optimizers.Adagrad(learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,name=\"Adagrad\",**kwargs)\n",
    "\n",
    "1. Adagrad is an optimizer with parameter-specific learning rates, i.e., relative to the frequency of a parameter getting updated during training. The more updates the smaller they are.\n",
    "\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. learning_rate: A Tensor, floating point value, or a schedule that is a tf.keras.optimizers.schedules.LearningRateSchedule. The learning rate.\n",
    "\n",
    "    \n",
    "2. initial_accumulator_value: A floating point value. Starting value for the accumulators, must be non-negative.\n",
    "\n",
    "    \n",
    "3. epsilon: A small floating point value to avoid zero denominator.\n",
    "\n",
    "    \n",
    "4. name: Optional name prefix for the operations created when applying gradients. Defaults to \"Adagrad\".\n",
    "\n",
    "    \n",
    "5. **kwargs: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\". \"clipnorm\" (float) clips gradients by norm; \"clipvalue\" (float) clips gradients by value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.90005"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "opt= tf.keras.optimizers.Adagrad(learning_rate=0.1, epsilon=1e-7)\n",
    "var1=tf.Variable(10.0)\n",
    "loss= lambda: (var1**2)/2.0\n",
    "\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adamax \n",
    "\n",
    "syntax: tf.keras.optimizers.Adamax(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\", **kwargs)\n",
    "    \n",
    "1. It is a variant of Adam based on infinity norm. For models with embeddings, Adamax gives better performance than Adam.\n",
    "\n",
    "# Algorithm \n",
    "\n",
    "# Initialization  \n",
    "\n",
    "m = 0  # Initialize initial 1st moment vector\n",
    "\n",
    "v = 0  # Initialize the exponentially weighted infinity norm\n",
    "\n",
    "t = 0  # Initialize timestep\n",
    "\n",
    "# Update rule\n",
    "\n",
    "t += 1\n",
    "\n",
    "m = beta1 * m + (1 - beta) * g\n",
    "\n",
    "v = max(beta2 * v, abs(g))\n",
    "\n",
    "current_lr = learning_rate / (1 - beta1 ** t)\n",
    "\n",
    "w = w - current_lr * m / (v + epsilon)\n",
    "\n",
    "# Key Points\n",
    "\n",
    "1. Similarly to Adam, the epsilon is added for numerical stability (especially to get rid of division by zero when v_t == 0).\n",
    "\n",
    "\n",
    "2. In contrast to Adam, the sparse implementation of this algorithm (used when the gradient is an IndexedSlices object, typically because of tf.gather or an embedding lookup in the forward pass) only updates variable slices and corresponding m_t, v_t terms when that part of the variable was used in the forward pass. This means that the sparse behavior is contrast to the dense behavior (similar to some momentum implementations which ignore momentum unless a variable slice was actually used).\n",
    "\n",
    "# Arguments\n",
    "\n",
    "\n",
    "1. learning_rate: A Tensor, floating point value, or a schedule that is a tf.keras.optimizers.schedules.LearningRateSchedule. The learning rate.\n",
    "\n",
    "    \n",
    "2. beta_1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
    "\n",
    "    \n",
    "3. beta_2: A float value or a constant float tensor. The exponential decay rate for the exponentially weighted infinity norm.\n",
    "\n",
    "    \n",
    "4. epsilon: A small constant for numerical stability.\n",
    "\n",
    "    \n",
    "5. name: Optional name for the operations created when applying gradients. Defaults to \"Adamax\".\n",
    "    \n",
    "    \n",
    "6. **kwargs: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\". \"clipnorm\" (float) clips gradients by norm; \"clipvalue\" (float) clips gradients by value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "opt= tf.keras.optimizers.Adamax(learning_rate=0.1)\n",
    "var1=tf.Variable(10.0)\n",
    "loss= lambda: (var1**2)/2.0\n",
    "\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nadam \n",
    "\n",
    "syntax: tf.keras.optimizers.Nasam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Nadam\", **kwargs)\n",
    "\n",
    "1. Nadam is Adam with Nesterov momentum.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "\n",
    "1. learning_rate: A Tensor or a floating point value. The learning rate.\n",
    "    \n",
    "    \n",
    "2. beta_1: A float value or a constant float tensor. The exponential decay rate for the 1st moment estimates.\n",
    "    \n",
    "    \n",
    "3. beta_2: A float value or a constant float tensor. The exponential decay rate for the exponentially weighted infinity norm.\n",
    "\n",
    "    \n",
    "4. epsilon: A small constant for numerical stability.\n",
    "\n",
    "    \n",
    "5. name: Optional name for the operations created when applying gradients. Defaults to \"Nadam\".\n",
    "\n",
    "    \n",
    "6. **kwargs: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\". \"clipnorm\" (float) clips gradients by norm; \"clipvalue\" (float) clips gradients by value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "opt= tf.keras.optimizers.Nadam(learning_rate=0.1)\n",
    "var1=tf.Variable(10.0)\n",
    "loss= lambda: (var1**2)/2.0\n",
    "\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.894355"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "opt= tf.keras.optimizers.Nadam(learning_rate=0.1, beta_1=0.9)\n",
    "var1=tf.Variable(10.0)\n",
    "loss= lambda: (var1**2)/2.0\n",
    "\n",
    "step_count = opt.minimize(loss, [var1]).numpy()\n",
    "var1.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FTRL\n",
    "\n",
    "syntax: \n",
    "\n",
    "**tf.keras.optimizers.Ftrl(\n",
    "    learning_rate=0.001,\n",
    "    learning_rate_power=-0.5,\n",
    "    initial_accumulator_value=0.1,\n",
    "    l1_regularization_strength=0.0,\n",
    "    l2_regularization_strength=0.0,\n",
    "    name=\"Ftrl\",\n",
    "    l2_shrinkage_regularization_strength=0.0,\n",
    "    beta=0.0,\n",
    "    **kwargs)**\n",
    "\n",
    "    \n",
    "# Arguments\n",
    "\n",
    "\n",
    "1. learning_rate: A Tensor, floating point value, or a schedule that is a tf.keras.optimizers.schedules.LearningRateSchedule. The learning rate.\n",
    "\n",
    "\n",
    "2. learning_rate_power: A float value, must be less or equal to zero. Controls how the learning rate decreases during training. Use zero for a fixed learning rate.\n",
    "    \n",
    "    \n",
    "3. initial_accumulator_value: The starting value for accumulators. Only zero or positive values are allowed.\n",
    "    \n",
    "    \n",
    "4. l1_regularization_strength: A float value, must be greater than or equal to zero.\n",
    "    \n",
    "    \n",
    "5. l2_regularization_strength: A float value, must be greater than or equal to zero.\n",
    "    \n",
    "    \n",
    "6. name: Optional name prefix for the operations created when applying gradients. Defaults to \"Ftrl\".\n",
    "    \n",
    "    \n",
    "7. l2_shrinkage_regularization_strength: A float value, must be greater than or equal to zero. This differs from L2 above in that the L2 above is a stabilization penalty, whereas this L2 shrinkage is a magnitude penalty. When input is sparse shrinkage will only happen on the active weights.\n",
    "    \n",
    "    \n",
    "8. beta: A float value, representing the beta value from the paper.\n",
    "    \n",
    "    \n",
    "9. **kwargs: Keyword arguments. Allowed to be one of \"clipnorm\" or \"clipvalue\". \"clipnorm\" (float) clips gradients by norm; \"clipvalue\" (float) clips gradients by value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
