{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard class\n",
    "\n",
    "tf.keras.callbacks.TensorBoard(log_dir=\"logs\", histogra_freq=0, write_graph=True, write_images=False, update_freq=\"epoch\", profile_batch=2, embeddings_freq=0, embeddings_metadata=None)\n",
    "\n",
    "#this callback enables visualizations for tensorboard\n",
    "\n",
    "#This callback logs events for TensorBoard, including:\n",
    "\"\"\"\n",
    "    Metrics summary plots\n",
    "    Training graph visualization\n",
    "    Activation histograms\n",
    "    Sampled profiling\n",
    "\"\"\"\n",
    "#arguments\n",
    "\n",
    "\"\"\"\n",
    "1. log_dir: path of the directory where to save the log files to be parsed by tensorboard\n",
    "\n",
    "2. histogram_freq: frequency (in epochs) at which to compute activation and weight histograms for the layers of the model. if 0, histograms won't be computed. Validation (split) should be specified for visualization.\n",
    "\n",
    "3. write_graph: whether to visualize the graph in tensorboard.\n",
    "\n",
    "4. write_images: whether to write model weights as images in tensorboard.\n",
    "\n",
    "5. update_freq: 'batch' or 'epoch' or integer. When using 'batch', writes the losses and metrics to TensorBoard after each batch. The same applies for 'epoch'. If using an integer, let's say 1000, the callback will write the metrics and losses to TensorBoard every 1000 batches. Note that writing too frequently to TensorBoard can slow down your training.\n",
    "\n",
    "6. profile_batch: profile batches are used to compute the characteristics. profile_batch is a tuple or an integer (non-negative). positive integers signify the range of the profile. set it to 0 to disable.\n",
    "\n",
    "7. embeddings_freq: frequency (in epochs) at which the embeddings layer is to be visualized. if set to 0 then the layers won't be visualized.\n",
    "\n",
    "8. embeddings_metadata: a dictionary which maps layer name to a file name in which metadata for this embedding layer is saved. See the details about metadata files format. In case if the same metadata file is used for all embedding layers, string can be passed.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
    "# run the tensorboard command to view the visualizations.\n",
    "\n",
    "\n",
    "# profile a single batch, e.g. the 5th batch.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs',\n",
    "                                                      profile_batch=5)\n",
    "model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
    "# Now run the tensorboard command to view the visualizations (profile plugin).\n",
    "\n",
    "# profile a range of batches, e.g. from 10 to 20.\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs',\n",
    "                                                      profile_batch='10,20')\n",
    "model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
    "# Now run the tensorboard command to view the visualizations (profile plugin).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
