{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanSquaredError class\n",
    "\n",
    "syntax: tf.keras.losses.MeanSquaredError(reduction=\"auto\", name=\"mean_squared_error\")\n",
    "\n",
    "1. Computes the mean of squares of errors between labels and predictions.\n",
    "\n",
    "loss = square(y_true - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0.,1.], [0.,0.]]\n",
    "\n",
    "y_pred = [[1.,1.],[1.,0.]]\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError(reduction=\"sum\")\n",
    "\n",
    "mse1 = tf.keras.losses.MeanSquaredError(reduction=\"sum_over_batch_size\")\n",
    "\n",
    "o1=mse(y_true, y_pred).numpy()\n",
    "\n",
    "o2=mse1(y_true, y_pred).numpy()\n",
    " \n",
    "o1\n",
    "\n",
    "#o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanAbsoluteError class\n",
    "\n",
    "syntax: tf.keras.losses.MeanAbsoluteError(reduction=\"auto\", name=\"mean_absolute_error\")\n",
    "\n",
    "1. Computes the mean of absolute difference between labels and predictions.\n",
    "\n",
    "loss = abs(y_true - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0.,1.], [0.,0.]]\n",
    "\n",
    "y_pred = [[1.,1.],[1.,0.]]\n",
    "\n",
    "mse = tf.keras.losses.MeanAbsoluteError(reduction=\"sum\")\n",
    "\n",
    "mse1 = tf.keras.losses.MeanAbsoluteError(reduction=\"sum_over_batch_size\")\n",
    "\n",
    "o1=mse(y_true, y_pred).numpy()\n",
    "\n",
    "o2=mse1(y_true, y_pred).numpy()\n",
    " \n",
    "o1\n",
    "\n",
    "o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanAbsolutePercentageError class\n",
    "\n",
    "syntax: tf.keras.losses.MeanAbsolutePercentageError(reduction=\"auto\", name=\"mean_absolute_percentage_error\")\n",
    "\n",
    "1. Computes the mean absolute percentage error between y_true and y_pred.\n",
    "\n",
    "loss = 100 * abs(y_true - y_pred) / y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[2.,1.], [2.,3.]]\n",
    "\n",
    "y_pred = [[1.,1.],[1.,0.]]\n",
    "\n",
    "mse = tf.keras.losses.MeanAbsolutePercentageError(reduction=\"sum\")\n",
    "\n",
    "mse1 = tf.keras.losses.MeanAbsolutePercentageError(reduction=\"sum_over_batch_size\")\n",
    "\n",
    "o1=mse(y_true, y_pred).numpy()\n",
    "\n",
    "o2=mse1(y_true, y_pred).numpy()\n",
    " \n",
    "o1\n",
    "\n",
    "#o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanSquaredLogarithmicError class\n",
    "\n",
    "syntax: tf.keras.losses.MeanSquaredLogarithmicError(reduction=\"auto\", name=\"mean_squared_logarithmic_error\")\n",
    "\n",
    "1. Computes the mean squared logarithmic error between y_true and y_pred.\n",
    "\n",
    "loss = square(log(y_true + 1.) - log(y_pred + 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48045287"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0.,1.], [0.,0.]]\n",
    "\n",
    "y_pred = [[1.,1.],[1.,0.]]\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredLogarithmicError(reduction=\"sum\")\n",
    "\n",
    "mse1 = tf.keras.losses.MeanSquaredLogarithmicError(reduction=\"sum_over_batch_size\")\n",
    "\n",
    "o1=mse(y_true, y_pred).numpy()\n",
    "\n",
    "o2=mse1(y_true, y_pred).numpy()\n",
    " \n",
    "o1\n",
    "\n",
    "#o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CosineSimilarity class\n",
    "\n",
    "syntax: tf.keras.losses.CosineSimilarity(axis=-1, reduction=\"auto\", name=\"cosine_similarity\")\n",
    "    \n",
    "    \n",
    "1. Note that it is a number between -1 and 1. When it is a negative number between -1 and 0, 0 indicates orthogonality and values closer to -1 indicate greater similarity. The values closer to 1 indicate greater dissimilarity. This makes it usable as a loss function in a setting where you try to maximize the proximity between predictions and targets. If either y_true or y_pred is a zero vector, cosine similarity will be 0 regardless of the proximity between predictions and targets.\n",
    "\n",
    "formula is gives by\n",
    "\n",
    "loss = -sum(l2_norm(y_true) * l2_norm(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70710677"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0.,1.], [1.,1.]]\n",
    "\n",
    "y_pred = [[1.,0.],[1.,1.]]\n",
    "\n",
    "mse = tf.keras.losses.CosineSimilarity(axis=0)\n",
    "\n",
    "mse1 = tf.keras.losses.CosineSimilarity(reduction=\"sum_over_batch_size\")\n",
    "\n",
    "o1=mse(y_true, y_pred).numpy()\n",
    "\n",
    "o2=mse1(y_true, y_pred).numpy()\n",
    " \n",
    "o1\n",
    "\n",
    "#o2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean_squared_error function\n",
    "\n",
    "syntax: tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "1. Computes the mean squared error between labels and predictions.\n",
    "\n",
    "2. After computing the squared distance between the inputs, the mean value over the last dimension is returned.\n",
    "\n",
    "loss = mean(square(y_true - y_pred), axis=-1)\n",
    "\n",
    "# Returns\n",
    "\n",
    "1. Mean squared error values. shape = [batch_size, d0, .. dN-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32535351, 0.76704734])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.random.randint(0,2, size=(2,3))\n",
    "\n",
    "y_pred = np.random.random(size=(2,3))\n",
    "\n",
    "loss = tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "loss.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean_absolute_error function\n",
    "\n",
    "syntax: tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "1. Computes the mean absolute error between labels and predictions.\n",
    "\n",
    "loss = mean(abs(y_true - y_pred), axis=-1)\n",
    "\n",
    "# Returns\n",
    "\n",
    "1. Mean squared error values. shape = [batch_size, d0, .. dN-1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45770356, 0.43356183])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.random.randint(0,2, size=(2,3))\n",
    "\n",
    "y_pred = np.random.random(size=(2,3))\n",
    "\n",
    "loss = tf.keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "loss.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean_absolute_percentage_error function\n",
    "\n",
    "syntax: tf.keras.losses.mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "1. Computes the mean absolute percentage error between y_true and y_pred.\n",
    "\n",
    "loss = 100 * mean(abs((y_true - y_pred) / y_true), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.32789833e+08, 3.42894185e+08])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.random.randint(0,2, size=(2,3))\n",
    "\n",
    "y_true = np.maximum(y_true, 1e-7)\n",
    "\n",
    "y_pred = np.random.random(size=(2,3))\n",
    "\n",
    "loss = tf.keras.losses.mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "loss.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean_squared_logarithmic_error function\n",
    "\n",
    "syntax: tf.keras.losses.mean_squared_logarithmic_error(y_true, y_pred)\n",
    "\n",
    "1. Computes the mean squared logarithmic error between y_true and y_pred.\n",
    "\n",
    "loss = mean(square(log(y_true + 1) - log(y_pred + 1)), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12001915, 0.15088187])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.random.randint(0,2, size=(2,3))\n",
    "\n",
    "y_pred = np.random.random(size=(2,3))\n",
    "\n",
    "loss = tf.keras.losses.mean_squared_logarithmic_error(y_true, y_pred)\n",
    "\n",
    "assert loss.shape ==(2,)\n",
    "\n",
    "y_true = np.maximum(y_true, 1e-7)\n",
    "\n",
    "y_pred = np.maximum(y_true, 1e-7)\n",
    "\n",
    "loss.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cosine_similarity function\n",
    "\n",
    "syntax: tf.keras.losses.cosine_similarity(y_true, y_pred, axis=-1)\n",
    "\n",
    "1. Computes the cosine similarity between labels and predictions.\n",
    "\n",
    "loss = -sum(l2_norm(y_true) * l2_norm(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.9999999403953552, -0.9999999403953552]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0.,1.],[1.,1.],[1.,1.]]\n",
    "\n",
    "y_pred = [[1.,0.],[1.,1.],[-1.,-1.]]\n",
    "\n",
    "loss =tf.keras.losses.cosine_similarity(y_true, y_pred, axis=-1)\n",
    "\n",
    "loss.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huber class\n",
    "\n",
    "synatx: tf.keras.losses.Huber(delta=1.0, reduction=\"auto\", name=\"huber_loss\")\n",
    "\n",
    "1. Computes the Huber loss between y_true and y_pred.\n",
    "\n",
    "For each value x in error = y_true - y_pred:\n",
    "\n",
    "loss = 0.5 * x^2                  if |x| <= d\n",
    "loss = 0.5 * d^2 + d * (|x| - d)  if |x| > d\n",
    "\n",
    "where d is delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.155"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0,1],[0,0]]\n",
    "\n",
    "y_pred = [[0.6,0.4],[0.4,0.6]]\n",
    "\n",
    "h = tf.keras.losses.Huber()\n",
    "\n",
    "h(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# huber function\n",
    "\n",
    "syntax: tf.keras.losses.huber(y_true, y_pred, delta=1.0)\n",
    "\n",
    "1. Computes Huber loss value.\n",
    "\n",
    "For each value x in error = y_true - y_pred:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogCosh class\n",
    "\n",
    "synatx: tf.keras.losses.LogCosh(reduction=\"auto\", name=\"log_cosh\")\n",
    "\n",
    "1. Computes the logarithm of the hyperbolic cosine of the prediction error.\n",
    "\n",
    "logcosh = log((exp(x) + exp(-x))/2), where x is the error y_pred - y_true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10844523"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_true = [[0.,1.],[0.,0.]]\n",
    "\n",
    "y_pred = [[1.,1.],[0.,0.]]\n",
    "\n",
    "l = tf.keras.losses.LogCosh()\n",
    "\n",
    "l(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log_cosh function\n",
    "\n",
    "syntax: tf.keras.losses.log_cosh(y_true, y_pred)\n",
    "\n",
    "1. Logarithm of the hyperbolic cosine of the prediction error.\n",
    "\n",
    "log(cosh(x)) is approximately equal to (x ** 2) / 2 for small x \n",
    "\n",
    "and to abs(x) - log(2) for large x. \n",
    "\n",
    "2. This means that 'logcosh' works mostly like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = np.random.random(size=(2, 3))\n",
    "y_pred = np.random.random(size=(2, 3))\n",
    "loss = tf.keras.losses.logcosh(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "x = y_pred - y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
