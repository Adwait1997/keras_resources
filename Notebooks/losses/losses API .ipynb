{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "\n",
    "1. While training a model, an error is calculated at the end of each epoch between the predicted output and the true output. Applying mathematical operations like MSE, RMSE on the error tend to produce different loss functions that can be used as per the application/task.\n",
    "\n",
    "\n",
    "2. Purpose of loss function is to compute the quantity that a model should seek to minimize during training.\n",
    "\n",
    "Loss functions are divided into 3 classes\n",
    "\n",
    "1. Probabilistic losses\n",
    "\n",
    "2. Regression Losses\n",
    "\n",
    "3. Hinge losses\n",
    "\n",
    "\n",
    "A loss is a callable with arguments loss_fn(y_true, y_pred, sample_weight=None):\n",
    "\n",
    "\n",
    "1. y_true: Ground truth values, of shape (batch_size, d0, ... dN). For sparse loss functions, such as sparse categorical crossentropy, the shape should be (batch_size, d0, ... dN-1)\n",
    "    \n",
    "\n",
    "2. y_pred: The predicted values, of shape (batch_size, d0, .. dN).\n",
    "    \n",
    "    \n",
    "3. sample_weight: Optional sample_weight acts as reduction weighting coefficient for the per-sample losses. If a scalar is provided, then the loss is simply scaled by the given value. If sample_weight is a tensor of size [batch_size], then the total loss for each sample of the batch is rescaled by the corresponding element in the sample_weight vector. If the shape of sample_weight is (batch_size, d0, ... dN-1) (or can be broadcasted to this shape), then each loss element of y_pred is scaled by the corresponding value of sample_weight. (Note ondN-1: all loss functions reduce by 1 dimension, usually axis=-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usage with compile() and fit() method\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(64, kernel_initializer='uniform', input_shape=(10,)))\n",
    "\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
