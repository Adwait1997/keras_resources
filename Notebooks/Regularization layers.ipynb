{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f021c9dcaf1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#dropout class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#this randomly sets input units to 0 with a frequency of rate at each step during the training time. which helps prevent overfitting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#dropout class\n",
    "#method \n",
    "tf.keras.layers.Dropout(rate, noise_shape=None, seed=None)\n",
    "\n",
    "#this randomly sets input units to 0 with a frequency of rate at each step during the training time. which helps prevent overfitting.\n",
    "#inputs not set to zero are multiplied by a factor of 1/(1-rate)\n",
    "\n",
    "#dropout layer only applies when the parameter training =True so that the values are only dropped when training takes place and not during the inference mode.\n",
    "\n",
    "#This is in contrast to setting trainable=False for a Dropout layer. trainable does not affect the layer's behavior, as Dropout does not have any variables/weights that can be frozen during training.\n",
    "\n",
    "#arguments\n",
    "\"\"\"\n",
    "rate: [float]. metric to set the rate at which the input units are to be dropped.\n",
    "\n",
    "noise_shape: 1D integer representing the shape of the mask that is to be multiplied by the input. \n",
    "\n",
    "seed: a python [integer] to use as random seed.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#call arguments\n",
    "\n",
    "\"\"\"\n",
    "1. input: tensor of any rank\n",
    "\n",
    "2. training:  Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing).\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.]\n",
      "  [1.]\n",
      "  [2.]\n",
      "  [3.]\n",
      "  [4.]]\n",
      "\n",
      " [[5.]\n",
      "  [6.]\n",
      "  [7.]\n",
      "  [8.]\n",
      "  [9.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(2, 5, 1), dtype=float32, numpy=\n",
       "array([[[ 0.       ],\n",
       "        [ 0.       ],\n",
       "        [ 4.0816326],\n",
       "        [ 6.122449 ],\n",
       "        [ 0.       ]],\n",
       "\n",
       "       [[10.204082 ],\n",
       "        [ 0.       ],\n",
       "        [14.285714 ],\n",
       "        [16.32653  ],\n",
       "        [ 0.       ]]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "layer = tf.keras.layers.Dropout(0.51, input_shape=(2,))\n",
    "data = np.arange(10).reshape(2,5,1).astype(np.float32)\n",
    "print(data)\n",
    "\n",
    "out = layer(data, training=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bf98efdb78e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#spatialdropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialDropout1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#This version performs the similar function, but, it froprs the entire 1D feature maps instead of in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rate' is not defined"
     ]
    }
   ],
   "source": [
    "#spatialdropout\n",
    "#method \n",
    "tf.keras.layers.SpatialDropout1D(rate)\n",
    "\n",
    "#This version performs the similar function, but, it froprs the entire 1D feature maps instead of in\n",
    "# If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.\n",
    "\n",
    "#Arguments\n",
    "\n",
    "#rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "\n",
    "#Call arguments\n",
    "\n",
    "#inputs: A 3D tensor.\n",
    "#training: Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing).\n",
    "\n",
    "#Input shape\n",
    "\n",
    "#3D tensor with shape: (samples, timesteps, channels)\n",
    "\n",
    "#Output shape\n",
    "\n",
    "#Same as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninputs: 4D tensor\\n\\ntraining: [boolean] whether the layer should run in training or inference mode.\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spatialDropout2D\n",
    "tf.keras.layers.SpatialDropout2D(rate, data_format=None)\n",
    "\n",
    "#this eliminates entire 2D feature maps instead of individual elements.\n",
    "\n",
    "#call arguments \n",
    "\"\"\"\n",
    "inputs: 4D tensor\n",
    "\n",
    "training: [boolean] whether the layer should run in training or inference mode.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#input shape\n",
    "\n",
    "#4D tensor with shape: (samples, channels, rows, cols) if data_format='channels_first' or 4D tensor with shape: (samples, rows, cols, channels) if data_format='channels_last'.\n",
    "\n",
    "#output shape\n",
    "\n",
    "#same as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-25af5c0f08d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#spatialDropout2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpatialDropout3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#this eliminates entire 3D feature maps instead of individual elements.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rate' is not defined"
     ]
    }
   ],
   "source": [
    "#spatialDropout2D\n",
    "tf.keras.layers.SpatialDropout3D(rate, data_format=None)\n",
    "\n",
    "#this eliminates entire 3D feature maps instead of individual elements.\n",
    "\n",
    "#call arguments \n",
    "\"\"\"\n",
    "inputs: 5D tensor\n",
    "\n",
    "training: [boolean] whether the layer should run in training or inference mode.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#input shape\n",
    "\n",
    "#5D tensor with shape: (samples, channels, dim1, dim2, dim3) if data_format='channels_first' or 5D tensor with shape: (samples, dim1, dim2, dim3, channels) if data_format='channels_last'.\n",
    "\n",
    "#output shape\n",
    "\n",
    "#same as input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-882fcff41da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#this layer applies 1-centered gaussian noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rate' is not defined"
     ]
    }
   ],
   "source": [
    "#gaussianDropout\n",
    "\n",
    "#method\n",
    "\n",
    "tf.keras.layers.GaussianDropout(rate)\n",
    "\n",
    "#this layer applies 1-centered gaussian noise\n",
    "\n",
    "#its only active during training time\n",
    "\n",
    "#arguments\n",
    "\n",
    "\"\"\"\n",
    "rate: [float] drop probability. the multiplicative noise will have standard deviation sqrt(rate/ (1-rate))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#call arguments\n",
    "\n",
    "\"\"\"\n",
    "1. input: tensor of any rank\n",
    "\n",
    "2. training:  Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Input shape\n",
    "\n",
    "#Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "#Output shape\n",
    "\n",
    "#Same shape as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stddev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2fb0ad08ccdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#apply additive zero-centered Gaussian noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stddev' is not defined"
     ]
    }
   ],
   "source": [
    "#GaussianNoise \n",
    "\n",
    "#method\n",
    "\n",
    "tf.keras.layers.GaussianNoise(stddev)\n",
    "\n",
    "#apply additive zero-centered Gaussian noise\n",
    "\n",
    "#This is useful to mitigate overfitting (you could see it as a form of random data augmentation). Gaussian Noise (GS) is a natural choice as corruption process for real valued inputs.\n",
    "\n",
    "#arguments\n",
    "\n",
    "\"\"\"\n",
    "stddev : [float] stddev of the noise distribution\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#call arguments\n",
    "\n",
    "\"\"\"\n",
    "1. input: tensor of any rank\n",
    "\n",
    "2. training:  Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Input shape\n",
    "\n",
    "#Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "#Output shape\n",
    "\n",
    "#Same shape as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    l1: L1 regularization factor (positive float).\\n    l2: L2 regularization factor (positive float).\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#activityregularization \n",
    "\n",
    "#method\n",
    "tf.keras.layers.ActivityRegularization(l1=0.0, l2=0.0)\n",
    "\n",
    "#Layer that applies an update to the cost function based input activity.\n",
    "\n",
    "#Arguments\n",
    "\"\"\"\n",
    "    l1: L1 regularization factor (positive float).\n",
    "    l2: L2 regularization factor (positive float).\n",
    "\"\"\"\n",
    "#call arguments\n",
    "\n",
    "\"\"\"\n",
    "1. input: tensor of any rank\n",
    "\n",
    "2. training:  Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Input shape\n",
    "\n",
    "#Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "#Output shape\n",
    "\n",
    "#Same shape as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphaDropout \n",
    "\n",
    "tf.keras.layers.AlphaDropout(rate, noise_shape=None, seed=None)\n",
    "\n",
    "#Alpha Dropout is a Dropout that keeps mean and variance of inputs to their original values, in order to ensure the self-normalizing property even after this dropout. Alpha Dropout fits well to Scaled Exponential Linear Units by randomly setting activations to the negative saturation value.\n",
    "\n",
    "#arguments\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    rate: float, drop probability (as with Dropout). The multiplicative noise will have standard deviation sqrt(rate / (1 - rate)).\n",
    "    seed: A Python integer to use as random seed.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#call arguments\n",
    "\n",
    "\"\"\"\n",
    "1. input: tensor of any rank\n",
    "\n",
    "2. training:  Python boolean indicating whether the layer should behave in training mode (adding dropout) or in inference mode (doing nothing).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Input shape\n",
    "\n",
    "#Arbitrary. Use the keyword argument input_shape (tuple of integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "#Output shape\n",
    "\n",
    "#Same shape as input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
