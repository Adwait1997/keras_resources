{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression metrics\n",
    "\n",
    "\n",
    "# MeanSquaredError class\n",
    "\n",
    "\n",
    "\n",
    "SYNTAX: tf.keras.metrics.MeanSquaredError(name=\"mean_squared_error\", dtype=None)\n",
    "\n",
    "\n",
    "    \n",
    "1. Computes the mean squared error between y_true and y_pred.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "    \n",
    "2. dtype: (Optional) data type of the metric result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "import tensorflow as tf\n",
    "m=tf.keras.metrics.MeanSquaredError(name=\"mean_squared_error\", dtype=None)\n",
    "\n",
    "m.update_state([[0,1],[0,0]], [[1,1],[0,0]])\n",
    "\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RootMeanSquaredError class\n",
    "\n",
    "\n",
    "\n",
    "SYNTAX: tf.keras.metrics.RootMeanSquaredError(name=\"root_mean_squared_error\", dtype=None)\n",
    "\n",
    "\n",
    "    \n",
    "1. Computes the root mean squared error between y_true and y_pred.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "    \n",
    "2. dtype: (Optional) data type of the metric result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "import tensorflow as tf\n",
    "m=tf.keras.metrics.RootMeanSquaredError(name=\"root_mean_squared_error\", dtype=None)\n",
    "\n",
    "m.update_state([[0,1],[0,0]], [[1,1],[0,0]])\n",
    "\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanAbsoluteError class\n",
    "\n",
    "syntax: tf.keras.metrics.MeanAbsoluteError(name=\"mean_absolute_error\", dtype=None)\n",
    "\n",
    "    \n",
    "1. Computes the mean absolute error between the labels and predictions.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "\n",
    "2. dtype: (Optional) data type of the metric result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "m=tf.keras.metrics.MeanAbsoluteError()\n",
    "\n",
    "m.update_state([[0,1],[0,0]],[[1,1],[0,0]])\n",
    "\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanAbsolutePercentageError class\n",
    "\n",
    "syntax: tf.keras.metrics.MeanAbsolutePercentageError(name=\"mean_absolute_percentage_error\", dtype=None)\n",
    "\n",
    "\n",
    "1. Computes the mean absolute percentage error between y_true and y_pred.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "    \n",
    "2. dtype: (Optional) data type of the metric result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000000.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "m=tf.keras.metrics.MeanAbsolutePercentageError()\n",
    "\n",
    "m.update_state([[0,1],[0,0]],[[1,1],[0,0]])\n",
    "\n",
    "m.result().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MeanSquaredLogarithmicError class\n",
    "\n",
    "syntax: tf.keras.metrics.MeanSquaredLogarithmicError(name=\"mean_squared_logarithmic_error\", dtype=None)\n",
    "\n",
    "1. Computes the mean squared logarithmic error between y_true and y_pred.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "    \n",
    "2. dtype: (Optional) data type of the metric result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12011322"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "m=tf.keras.metrics.MeanSquaredLogarithmicError()\n",
    "\n",
    "m.update_state([[0,1],[0,0]],[[1,1],[0,0]])\n",
    "\n",
    "m.result().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CosineSimilarity class\n",
    "\n",
    "syntax: tf.keras.metrics.CosineSimilarity(name=\"cosine_similarity\", dtype=None, axis=-1)\n",
    "\n",
    "    \n",
    "# Formula\n",
    "\n",
    "cosine similarity = (a . b) / ||a|| ||b||\n",
    "\n",
    "1. This metric keeps the average cosine similarity between predictions and labels over a stream of data.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "    \n",
    "    \n",
    "2. dtype: (Optional) data type of the metric result.\n",
    "    \n",
    "    \n",
    "3. axis: (Optional) Defaults to -1. The dimension along which the cosine similarity is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999997"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "m= tf.keras.metrics.CosineSimilarity(axis=-1)\n",
    "\n",
    "m.update_state([[0.,1.],[1.,1.]], [[1.,0.],[1.,1.]])\n",
    "\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogCoshError class\n",
    "\n",
    "syntax: tf.keras.metrics.LogCoshError(name=\"logcosh\", dtype=None)\n",
    "\n",
    "1. Computes the logarithm of the hyperbolic cosine of the prediction error.\n",
    "\n",
    "\n",
    "# Formula\n",
    "\n",
    "logcosh = log((exp(x) + exp(-x))/2), where x is the error (y_pred - y_true)\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "    \n",
    "    \n",
    "2. dtype: (Optional) data type of the metric result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10844523"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "m=tf.keras.metrics.LogCoshError()\n",
    "\n",
    "m.update_state([[0,1],[0,0]], [[1,1],[0,0]])\n",
    "\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
