{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are logits?\n",
    "\n",
    "Mathematically,  Logit is a function that maps probabilities ([0, 1]) to R ((-inf, inf))\n",
    "\n",
    "L = ln(p/1-p) => p=1/(1+e^(-L))\n",
    "\n",
    "Probability of 0.5 corresponds to a logit of 0. Negative logit correspond to probabilities less than 0.5, positive to > 0.5.\n",
    "\n",
    "\n",
    "In ML, it can be the vector of raw (non-normalized) predictions that a classification model generates, which is ordinarily then passed to a normalization function. If the model is solving a multi-class classification problem, logits typically become an input to the softmax function. The softmax function then generates a vector of (normalized) probabilities with one value for each possible class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic metrics\n",
    "\n",
    "**syntax: tf.keras.metrics.BinaryCrossentropy(name=\"binary_crossentropy\", dtype=None, from_logits=Falsse, label_smoothing=0)**\n",
    "    \n",
    "1. This computes crossentropy metric between the labels and predictions.\n",
    "\n",
    "\n",
    "2. This crossentropy metric calss is to beused when there are two label classes.\n",
    "\n",
    "\n",
    "# Arguments \n",
    "\n",
    "\n",
    "1. name: string for the metric\n",
    "\n",
    "\n",
    "2. dtype: data type of the result\n",
    "\n",
    "    \n",
    "3. from_logits: whether the output is expected to be a logit tensor. By default, the output encodes a rough probability distribution.\n",
    "\n",
    "    \n",
    "4. label_smoothing: Float[0, 1]. \n",
    "    \n",
    "    for label_values > 0 the confidence is reduced\n",
    "    \n",
    "    e.g. label_smoothing=0.2 means we can use a value (slighltly greater than) the original value, i.e., 0.1 for label 0 and 0.9 for label 1.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71355796"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "\n",
    "import tensorflow as tf\n",
    "m= tf.keras.metrics.BinaryCrossentropy()\n",
    "\n",
    "m.update_state([[0,1],[0,1]],[[0.6,0.4],[0.4,0.6]])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Crossentropy\n",
    "\n",
    "**syntax: tf.keras.metrics.CategoricalCrossentropy(name=\"categorical_crossentropy\", dtype=None, from_logits=False, label_smoothing=0)**\n",
    "\n",
    "1. Computes the crossentropy metric between the labels and predictions.\n",
    "\n",
    "\n",
    "2. This is the crossentropy metric class to be used when there are multiple label classes (2 or more). Here we assume that labels are given as a one_hot representation. eg., When labels values are [2, 0, 1], y_true = [[0, 0, 1], [1, 0, 0], [0, 1, 0]].\n",
    " \n",
    "\n",
    "# Arguments \n",
    "\n",
    "\n",
    "1. name: string for the metric\n",
    "\n",
    "\n",
    "2. dtype: data type of the result\n",
    "\n",
    "    \n",
    "3. from_logits: whether the output is expected to be a logit tensor. By default, the output encodes a rough probability distribution.\n",
    "\n",
    "    \n",
    "4. label_smoothing: Float[0, 1]. \n",
    "    \n",
    "    for label_values > 0 the confidence is reduced\n",
    "    \n",
    "    e.g. label_smoothing=0.2 means we can use a value (slighltly greater than) the original value, i.e., 0.1 for label 0 and 0.9 for label 1.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3585534"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage \n",
    "\n",
    "import tensorflow as tf\n",
    "m= tf.keras.metrics.CategoricalCrossentropy()\n",
    "\n",
    "m.update_state([[0,1,0],[0,0,1]],[[0.05, 0.95, 0],[0.1, 0.8, 0.1]])\n",
    "m.result().numpy()\n",
    "\n",
    "m.reset_states()\n",
    "\n",
    "m.update_state([[1,0,1],[0,0,1]], [[0.05,0.03,0.01],[0.04,0.06,0.09]], sample_weight=([0.3,0.7]))\n",
    "\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparseCategoricalCrossentropy \n",
    "\n",
    "syntax: tf.keras.metrics.SparseCategoricalCrossentropy(name=\"sparse_categorical_crossentropy\", dtype=None, from_logits=False, axis=-1)\n",
    "    \n",
    "1. computes the crossetropy between the labels and predictions.\n",
    "\n",
    "\n",
    "2. Use this crossentropy metric when there are two or more label classes. We expect labels to be provided as integers. If you want to provide labels using one-hot representation, please use CategoricalCrossentropy metric. There should be number of classes floating point values per feature for y_pred and a single floating point value per feature for y_true.\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "\n",
    "\n",
    "2. dtype: (Optional) data type of the metric result.\n",
    "\n",
    "\n",
    "3. from_logits: (Optional) Whether output is expected to be a logits tensor. By default, we consider that output encodes a probability distribution.\n",
    "\n",
    "\n",
    "4. axis: (Optional) Defaults to -1. The dimension along which the metric is computed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1769392"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage \n",
    "\n",
    "import tensorflow as tf\n",
    "m= tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "\n",
    "m.update_state([1,2],[[0.05, 0.95, 0],[0.1, 0.8, 0.1]])\n",
    "m.result().numpy()\n",
    "\n",
    "#m.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KLDivergence class\n",
    "\n",
    "syntax: tf.keras.metrics.KLDivergence(name=\"kullback_leibler_divergence\", dtype=None)\n",
    "\n",
    "1. Computes Kullback-Leibler divergence metric between y_true and y_pred.\n",
    "\n",
    "\n",
    "2. metric = y_true * log(y_true / y_pred)\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "\n",
    "    \n",
    "2. dtype: (Optional) data type of the metric result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71355665"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "\n",
    "import tensorflow as tf\n",
    "m= tf.keras.metrics.KLDivergence()\n",
    "\n",
    "m.update_state([[1,1],[0,0]], [[0.6,0.4],[0.4,0.6]])\n",
    "\n",
    "m.result().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson\n",
    "\n",
    "syntax: tf.keras.metrics.Poisson(name=\"poisson\", dtype=None)\n",
    "    \n",
    "1. Computes the Poisson metric between y_true and y_pred.\n",
    "\n",
    "\n",
    "2. metric = y_pred - y_true * log(y_pred)\n",
    "\n",
    "\n",
    "# Arguments\n",
    "\n",
    "\n",
    "1. name: (Optional) string name of the metric instance.\n",
    "    \n",
    "\n",
    "2. dtype: (Optional) data type of the metric result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999997"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example\n",
    "\n",
    "m=tf.keras.metrics.Poisson()\n",
    "\n",
    "m.update_state([[0,1],[0,0]], [[1,1],[0,0]])\n",
    "\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
