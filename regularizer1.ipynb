{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer weight regularizers\n",
    "#regularizers are used to penalize the layer's bias, kernel, and output during optimization.\n",
    "#regularizer adds the penalties to the loss\n",
    "\n",
    "#designing and training a neural network model to perform a certain task is challenging as it involves complexities. Certain complexities unable the model to generalize well giving rise to Overfitting. Regularizers penalize the layer's parameters thereby reducing the overfitting and making learning easy.\n",
    " \n",
    "import tensorflow as tf    \n",
    "\"\"\"\n",
    "kernel_regularizer: for kernels of the layers \n",
    "bias_regularizer: for the layer's bias\n",
    "activity_regularizer: for the layer's output\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "layer = layers.Dense(10, kernel_regularizer= 'l1_l2', bias_regularizer= 'l2', activity_regularizer='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.25, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "layers = tf.keras.layers.Dense(5, kernel_initializer='ones', kernel_regularizer=tf.keras.regularizers.l1(0.01), activity_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "input_ = tf.ones(shape=(5,5))*2\n",
    "out = layers(input_)\n",
    "\n",
    "print(tf.math.reduce_sum(layers.losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1\n",
    "#method: tf.keras.regularizers.l1(l1=0.01)\n",
    "\n",
    "#logic: loss = l1*reduce_sum(abs(x))\n",
    "\n",
    "#when applied to the layer\n",
    "\n",
    "dense = tf.keras.layers.Dense(64, kernel_regularizer='l1')\n",
    "\n",
    "#default value for l1 is 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l2 \n",
    "#method: tf.keras.regularizers.l2(l2=0.01)\n",
    "\n",
    "#logic: loss= l2*reduce_sum(square(x))\n",
    "\n",
    "#when applied to the layer\n",
    "\n",
    "dense = tf.keras.layers.Dense(64, kernel_regularizer='l2')\n",
    "\n",
    "#default value for l1 is 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1_l2\n",
    "#method: tf.keras.regularizers.l1_l2(l1=0.01, l2=0.01)\n",
    "\n",
    "#logic: loss = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
