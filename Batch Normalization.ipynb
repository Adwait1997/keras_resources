{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f3d253f89618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m tf.keras.layers.BatchNormalization(axis=-1, momentum=0.09, \n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                    \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#batch_normalization\n",
    "\"\"\"\n",
    "Normalization is putting the data on single scale to be avoid the instability while training the neural network and the exploding gradient problem. The data is standardized as per the norms like calculating the mean, etc.\n",
    "Normalization is done on per layer basis and on the input and the output data in batches.\n",
    "\n",
    "\"\"\"\n",
    "#method \n",
    "tf.keras.layers.BatchNormalization(axis=-1, momentum=0.09, \n",
    "                                   \n",
    "                                   epsilon=0.001, center=True, scale=True, beta_initializer=\"zeros\", \n",
    "                                   gamma_initializer=\"ones\", moving_mean_initializer=\"zeros\", \n",
    "                                   moving_variance_initializer=\"ones\", beta_regularizer=None, \n",
    "                                   gamma_regularizer=None, beta_constraint=None, gamma_constraint=None, \n",
    "                                   renorm=False, renorm_clipping=None, renorm_momentum=0.99, fused=None, \n",
    "                                   trainable=True, virtual_batch_size=None, adjustment=None, name=None)\n",
    "\n",
    "\n",
    "#Note\n",
    "#During training stage\n",
    "\"\"\"\n",
    "When using model.fit() method and set the training parameter as true.\n",
    "The output (each channel) is normalized before passing it as an input to the subsequent layer.\n",
    "\n",
    "Normalization formula:\n",
    "\n",
    "(batch(input) - mean(bach))/ (variance(batch) + epsilon) * gamma + beta\n",
    "\n",
    "-> epsilon is small constant \n",
    "-> gamma is a learned scaling factor (can be turned off by using scale=False)\n",
    "-> beta is a learned offset factor (can be disabled by using center=False)\n",
    "\"\"\"\n",
    "\n",
    "#during inference stage\n",
    "\"\"\"\n",
    "when using the model.predict or model.evaluate() and setting the training argument as false.\n",
    "\n",
    "the layer normalizes its output by using a moving avg mean and standard deviation of the batches it saw during the training.\n",
    "\n",
    "#normalization formula\n",
    "\n",
    "(batch- self.moving_mean) / self.moving_var + eps) * gamma + beta\n",
    "\n",
    "-> self.moving_mean and self.moving_var are non trainable variables, i.e., they can't be optimized.\n",
    "\n",
    "-> moving_mean = moving_mean * momentum + mean(batch) * (1-momentum)\n",
    "\n",
    "-> moving_var = moving_var * momentum + var(batch) * (1-momentum)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#arguments\n",
    "\"\"\"\n",
    "1. Axis - [integer] which axis is to be normalized\n",
    "\n",
    "2. momentum - momentum for the moving average (mean & var)\n",
    "\n",
    "3. epsilon - [float] added to variance\n",
    "\n",
    "4. center - [boolean]. if true, beta is added as an offset\n",
    "\n",
    "5. scale - [boolean]. if true, gamma is multiplied\n",
    "\n",
    "6. renorm - [boolean]. whether to use batch normalization. it adds some extra variables during training.\n",
    "\n",
    "7. renorm clipping- A dictionary that may map keys 'rmax', 'rmin', 'dmax' to scalar Tensors used to clip the renorm correction. The correction (r, d) is used as corrected_value = normalized_value * r + d, with r clipped to [rmin, rmax], and d to [-dmax, dmax]. Missing rmax, rmin, dmax are set to inf, 0, inf, respectively.\n",
    "\n",
    "8. renorm_momentum: Momentum used to update the moving means and standard deviations with renorm. Unlike momentum, this affects training and should be neither too small (which would add noise) nor too large (which would give stale estimates). Note that momentum is still applied to get the means and variances for inference.\n",
    "\n",
    "9. fused - [boolean and None] meant for fused implementation.\n",
    "\n",
    "10. trainable - [boolean], if true the variables are marked as trainable\n",
    "\n",
    "11. virtual_batch_size - [int, None(default)], for creating virtual batches for the ghost batch normalization.\n",
    "\n",
    "12. adjustment - adjustment: A function taking the Tensor containing the (dynamic) shape of the input tensor and returning a pair (scale, bias) to apply to the normalized values (before gamma and beta), only during training. For example, if axis==-1, adjustment = lambda shape: ( tf.random.uniform(shape[-1:], 0.93, 1.07), tf.random.uniform(shape[-1:], -0.1, 0.1)) will scale the normalized value by up to 7% up or down, then shift the result by up to 0.1 (with independent scaling and bias for each feature but shared across all examples), and finally apply gamma and/or beta. If None, no adjustment is applied. Cannot be specified if virtual_batch_size is specified.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#call arguments \n",
    "\n",
    "\"\"\"\n",
    "1. inputs- input tensor of any rank\n",
    "\n",
    "2. training- [boolean] indicating whether the layer shoud behave in training or inference mode.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#notes\n",
    "\n",
    "\"\"\"\n",
    "1. integers, does not include the samples axis) when using this layer as the first layer in a model.\n",
    "\n",
    "2. Output shape Same shape as input. \n",
    "\n",
    "3. About setting layer.trainable = False on a BatchNormalization layer:\n",
    "\n",
    "-> The meaning of setting layer.trainable = False is to freeze the layer, i.e. its internal state will not change during training: its trainable weights will not be updated during fit() or train_on_batch(), and its state updates will not be run.\n",
    "\n",
    "Usually, this does not necessarily mean that the layer is run in inference mode (which is normally controlled by the training argument that can be passed when calling a layer). \"Frozen state\" and \"inference mode\" are two separate concepts.\n",
    "\n",
    "1. However, in the case of the BatchNormalization layer, setting trainable = False on the layer means that the layer will be subsequently run in inference mode (meaning that it will use the moving mean and the moving variance to normalize the current batch, rather than using the mean and variance of the current batch).\n",
    "\n",
    "This behavior has been introduced in TensorFlow 2.0, in order to enable layer.trainable = False to produce the most commonly expected behavior in the convnet fine-tuning use case.\n",
    "\n",
    "Note that: - This behavior only occurs as of TensorFlow 2.0. In 1.*, setting layer.trainable = False would freeze the layer but would not switch it to inference mode. \n",
    "\n",
    "- Setting trainable on an model containing other layers will recursively set the trainable value of all inner layers. \n",
    "\n",
    "- If the value of the trainable attribute is changed after calling compile() on a model, the new value doesn't take effect for this model until compile() is called again.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
